project_name: "coq-theorem-embedding"
experiment_name: "binary-class-bce-imm-codebert-freeze"
log_level: "INFO"

dataset_path: "./data/"
rankin_ds_path_statements: "./validationSet/data_events.json"
rankin_ds_path_references: "./validationSet/reference_premises.json"
samples_from_single_anchor: 10000
train_split: 0.8
val_split: 0.15
test_split: 0.05

model_name: "microsoft/codebert-base"
max_seq_length: 128
embedding_dim: 768
# If true, only train top layers
freeze_bert: true

margin: 0.25
# proof distance <= threshold -> positive
threshold_pos: 0.4
# proof distance >= threshold -> negative
threshold_neg: 0.65

epochs: 30
batch_size: 32
learning_rate: 4e-6
random_seed: 52

wandb:
  enabled: true
  project: "coq-embeddings"
  entity: "kozyrev-andreiii2016"
  tags: ["baseline", "triplet"]

evaluation:
  # For precision@k and recall@k
  k_values: [3, 5, 10]
  f_score_beta: 1